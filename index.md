---
layout:     page
title:
permalink:  /
---

<div class="row">
    <div class="col-sm-6 col-xs-12">
        <img src="/img/IMG_20210708_170708-01-01-01.jpeg">
    </div>
    <div class="col-sm-6 col-xs-12" style="margin-bottom: 0;">
        Pre-Doctoral Researcher<br>
        Google AI<br>
        vermashresth at google dot com
    </div>
</div>
<hr>

<a name="/news"></a>

# News

- [Mar 21] Joined [Google AI India](https://research.google/locations/india/) as Pre-Doctoral Reseacher! Working with [Milind Tambe](https://teamcore.seas.harvard.edu/tambe) within [AI for Social Good](https://ai.google/social-good/).
- [May 21] I'm volunteering at [ICLR 21](https://iclr.cc/Conferences/2021). See you at the help desk!
- [May 21] Presenting [Towards Sample Efficient Learners in Population based Referential Games through Action Advising- 
](#/advise) at AAMAS 2021 (Poster).
- [Feb 21] Invited as a Facilitator in [Reinforcement Learning Data Study Group](https://www.turing.ac.uk/events/reinforcement-learning-study-group-february-2021) at [The Alan Turing Institute, UK](www.turing.ac.uk)!
- [Dec 20] Released [JupyterProbe v0.1](https://pypi.org/project/jupyter-probe/). It helps monitor, manage and analyse notebook resource usage on Jupyter environments!
- [Aug 20] Joined United Health Group as Data Scientist!
- [July 20] Presenting [Emergence of Multilingualism in Population based Referential Games](#/multilingual) at Workshop on Language in Reinforcement Learning, ICML 2020.
- [Mar 20] I completed my Integrated Masters!
- [Feb 20] Presenting [Emergence of Writing Systems through Multi-Agent Cooperation](#/writing) at AAAI 2020 (Poster).
- [Jan 20] Presenting [Deep Reinforcement Learning for Single-Shot Diagnosis and Adaptation in Damaged Robots](#/diagnose-rl) at CoDS-COMAD 2020 (Oral).
- [Jan 20] Presenting [IIITM Face: A Database for Facial Attribute Detection in Constrained and Simulated Unconstrained Environments](#/iiitm) at CoDS-COMAD 2020 (Oral).

<div id="read-more-button">
    <a nohref>Read more</a>
</div>

<hr>

<a name="/bio"></a>

# Bio

I am a Pre-Doctoral Researcher at Google AI India.

My research focuses on reinforcement learning and multi-agent systems with application in robotics, public health and environmental conservation. On a fundamental research side, I'm interested in developing agents that learn behaviours which are transferable to real-world domains, are scalable through communication and are understandable and acceptable by humans.

Previously, I was a Data Scientist at United Health Group where I worked on modelling healthcare risks for millions of beneficiaries.
My CV is available [here][33].

<div class="row" id="timeline-logos"  style="margin-right:-1px">
    <div class="col-sm-3 ">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="//iiitm.ac.in/"><img style="width:60px;" src="/img/logos/Logo.jpg"></a>
        </div>
        <div class="logo-desc">
            IIIT Gwalior<br>
            2015 - 2020
        </div>
    </div>
    <div class="col-sm-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="//https://www.unitedhealthgroup.com/"><img style="width:200px;" style="width:200px;" src="/img/logos/uhg2.jpg"></a>
        </div>
        <div class="logo-desc">
            UnitedHealth Group<br>
            S2019, 2020-2021
        </div>
    </div>
    <div class="col-sm-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="//https://research.google/locations/india/"><img style="width:200px; height:200px;" src="/img/logos/gglai.png"></a>
        </div>
        <div class="logo-desc">
            Google AI<br>
            2021 - present
        </div>
    </div>
</div>


I graduated from [Indian Institute of Information Technology and Management Gwalior][31] in 2020.
During my undergrad years, both my Bachelor's and Master's Thesis had been graded as Outstanding. I have also actively contributed to Open Source Scientific Computing Community with feature additions and patches in projects such as OpenCV, AstroPy, SciPy, Shogun ML Toolkit, Chainer and TensorForce. 

On the side, I maintain [Jupyer Probe](https://pypi.org/project/jupyter-probe/), a library to monitor, manage, declare and analyse notebook resource usage on jupyter environments.
I am also an avid bird watcher and photographer and post pictures from my adventures on [Instagram][24].

[Blog posts from a previous life.](/archive)

---

<a name="/publications"></a>

# Publications

<a name="/spinconv"></a>
<h2 class="pubt">Rotation Invariant Graph Neural Networks using Spin Convolutions</h2>
<p class="pubd">
    <span class="authors">Muhammed Shuaibi, Adeesh Kolluru, Abhishek Das, Aditya Grover, Anuroop Sriram, Zachary Ulissi, C. Lawrence Zitnick</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2106.09575">Paper</a>
    </span>
</p>
<img src="/img/ocp/spinconv.jpg">
<hr>

<a name="/youdescribe-descriptions-1"></a>
<h2 class="pubt">Automated Video Description for Blind and Low Vision Users</h2>
<p class="pubd">
    <span class="authors">Aditya Bodi, Pooyan Fazli, Shasta Ihorn, Yue-Ting Siu, Andrew T Scott, Lothar Narins, Yash Kant, Abhishek Das, Ilmi Yoon</span><br>
    <span class="conf">CHI EA 2021</span><br>
    <span class="links">
        <a target="_blank" href="https://dl.acm.org/doi/10.1145/3411763.3451810">Paper</a>
    </span>
</p>
<img src="/img/youdescribe/chi_ea_system.png">
<hr>

<a name="/habitat-objnav"></a>
<h2 class="pubt">Auxiliary Tasks and Exploration Enable ObjectNav</h2>
<p class="pubd">
    <span class="authors">Joel Ye, Dhruv Batra, Abhishek Das, Erik Wijmans</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2104.04112">Paper</a>
        <a target="_blank" href="https://github.com/joel99/objectnav">Code</a>
        <a target="_blank" href="https://joel99.github.io/objectnav/">Website</a>
    </span>
</p>
<img src="/img/habitat/habitat-objnav.png">
<hr>

<a name="/forcenet"></a>
<h2 class="pubt">ForceNet: A Graph Neural Network for Large-Scale Quantum Calculations</h2>
<p class="pubd">
    <span class="authors">Weihua Hu, Muhammed Shuaibi, Abhishek Das, Siddharth Goyal, Anuroop Sriram, Jure Leskovec, Devi Parikh, C. Lawrence Zitnick</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2103.01436">Paper</a>
        <a target="_blank" href="https://opencatalystproject.org/">opencatalystproject.org</a>
    </span>
</p>
<img src="/img/ocp/forcenet.jpg">
<hr>

<a name="/ocp-dataset"></a>
<h2 class="pubt">The Open Catalyst 2020 (OC20) Dataset and Community Challenges</h2>
<p class="pubd">
    <span class="authors">Lowik Chanussot<sup>*</sup>, Abhishek Das<sup>*</sup>, Siddharth Goyal<sup>*</sup>, Thibaut Lavril<sup>*</sup>, Muhammed Shuaibi<sup>*</sup>, Morgane Riviére, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Aini Palizhati, Anuroop Sriram, Brandon Wood, Junwoong Yoon, Devi Parikh, C. Lawrence Zitnick, Zachary Ulissi</span><br>
    <span class="conf">ACS Catalysis 2021</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2010.09990">Paper</a>
        <a target="_blank" href="https://github.com/open-catalyst-project/ocp">Code</a>
        <a target="_blank" href="https://opencatalystproject.org/">opencatalystproject.org</a>
    </span>
</p>
<img src="/img/ocp/dataset.png">
<hr>

<a name="/ocp-whitepaper"></a>
<h2 class="pubt">An Introduction to Electrocatalyst Design using Machine Learning for Renewable Energy Storage</h2>
<p class="pubd">
    <span class="authors">C. Lawrence Zitnick, Lowik Chanussot, Abhishek Das, Siddharth Goyal, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Thibaut Lavril, Aini Palizhati, Morgane Riviére, Muhammed Shuaibi, Anuroop Sriram, Kevin Tran, Brandon Wood, Junwoong Yoon, Devi Parikh, Zachary Ulissi</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2010.09435">Paper</a>
        <a target="_blank" href="https://opencatalystproject.org/">opencatalystproject.org</a>
    </span>
    <!-- Press: -->
    <div class="row pressdiv" style="margin: 5px 0 0 0; line-height: 1.4em;">
        <a style="border-bottom: 0;" target="_blank" href="https://ai.facebook.com/blog/facebook-and-carnegie-mellon-launch-the-open-catalyst-project-to-find-new-ways-to-store-renewable-energy">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/fair2.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook and Carnegie Mellon launch .. to ... store renewable energy" by Larry Zitnick</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://fortune.com/2020/10/14/facebook-ai-open-catalyst-dataset-chemistry-renewable-energy/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/fortune.jpg" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook A.I. researchers push for a breakthrough in renewable energy storage" by Jeremy Kahn</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://engadget.com/facebook-deploys-its-ai-to-find-green-energy-storage-solutions-130041147.html">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/engadget.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook deploys its AI to find green energy storage solutions" by Andrew Tarantola</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://www.cnbc.com/2020/10/14/facebook-to-use-ai-in-bid-to-improve-renewable-energy-storage.html">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/cnbc.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook to use artificial intelligence in bid to improve renewable energy storage" by Sam Shead</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://venturebeat.com/2020/10/14/facebook-and-carnegie-mellon-launch-project-to-discover-better-ways-to-store-renewable-energy/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/venturebeat.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook and Carnegie Mellon launch project to ... store renewable energy" by Kyle Wiggers</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://www.cnet.com/news/facebook-plans-to-use-ai-to-help-fight-climate-change/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0 18px;">
                <img src="/img/logos/cnet.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook plans to use AI to help fight climate change" by Queenie Wong</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://syncedreview.com/2020/10/15/facebook-cmu-open-catalyst-project-applies-ai-to-renewable-energy-storage/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/synced.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Facebook & CMU Open Catalyst Project Applies AI to Renewable Energy Storage" by Fangyu Cai</span>
            </div>
        </a>
    </div>
</p>
<video autoplay loop src="/img/ocp/relaxation.mp4" width="95%"></video>
<hr>

<a name="/habitat-pointnav-aux"></a>
<h2 class="pubt">Auxiliary Tasks Speed Up Learning PointGoal Navigation</h2>
<p class="pubd">
    <span class="authors">Joel Ye, Dhruv Batra, Erik Wijmans*, Abhishek Das*</span><br>
    <span class="conf">CoRL 2020</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2007.04561">Paper</a>
        <a target="_blank" href="https://github.com/joel99/habitat-pointnav-aux">Code</a>
    </span>
</p>
<img src="/img/habitat/habitat-pointnav-aux.jpg">
<hr>

<a name="/visdial-bert"></a>
<h2 class="pubt">Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline</h2>
<p class="pubd">
    <span class="authors">Vishvak Murahari, Dhruv Batra, Devi Parikh, Abhishek Das</span><br>
    <span class="conf">ECCV 2020</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1912.02379">Paper</a>
        <a target="_blank" href="https://github.com/vmurahari3/visdial-bert">Code</a>
    </span>
</p>
<img src="/img/visdial/visdial-bert.jpg">
<hr>

<a name="/qa-probing"></a>
<h2 class="pubt">Probing Emergent Semantics in Predictive Agents via Question Answering</h2>
<p class="pubd">
    <span class="authors">Abhishek Das<sup>*</sup>, Federico Carnevale<sup>*</sup>,
        Hamza Merzic, Laura Rimell, Rosalia Schneider, Josh Abramson, Alden Hung,
        Arun Ahuja, Stephen Clark, Gregory Wayne, Felix Hill
    </span><br>
    <span class="conf">ICML 2020</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2006.01016">Paper</a>
        <a target="_blank" href="https://slideslive.com/38928261/probing-emergent-semantics-in-predictive-agents-via-question-answering">Presentation video</a>
        <a target="_blank" href="https://docs.google.com/presentation/d/1yjfu2YBLTwJZXG4IiBiws4Z0EIts4X0J5DrYmYpBQ0A/edit?usp=sharing">Slides</a>
    </span>
</p>
<img src="/img/qa-probing/qa-probing-teaser.jpg">
<hr>

<a name="/dancing-agents"></a>
<h2 class="pubt">Feel The Music: Automatically Generating A Dance For An Input Song</h2>
<p class="pubd">
    <span class="authors">Purva Tendulkar, Abhishek Das, Aniruddha Kembhavi, Devi Parikh</span><br>
    <span class="conf">ICCC 2020</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2006.11905">Paper</a>
        <a target="_blank" href="https://github.com/purvaten/feel-the-music">Code</a>
        <a target="_blank" href="https://sites.google.com/view/dancing-agents">Videos</a>
    </span>
</p>
<img src="/img/dancing-agents/dancing-agents-teaser.jpg">
<hr>

<a name="/ds-vic"></a>
<h2 class="pubt">IR-VIC: Unsupervised Discovery of Sub-goals for Transfer in RL</h2>
<p class="pubd">
    <span class="authors">Nirbhay Modhe, Prithvijit Chattopadhyay, Mohit Sharma, Abhishek Das, Devi Parikh, Dhruv Batra, Ramakrishna Vedantam</span><br>
    <span class="conf">IJCAI-PRICAI 2020, ICLR 2019 Task-Agnostic RL Workshop</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1907.10580">Paper</a>
    </span>
</p>
<img src="/img/ds-vic/teaser.jpg">
<hr>

<a name="/visdial-rl-plus-plus"></a>
<h2 class="pubt">Improving Generative Visual Dialog by Answering Diverse Questions</h2>
<p class="pubd">
    <span class="authors">Vishvak Murahari, Prithvijit Chattopadhyay, Dhruv Batra, Devi Parikh, Abhishek Das</span><br>
    <span class="conf">EMNLP 2019</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1909.10470">Paper</a>
        <a target="_blank" href="https://github.com/vmurahari3/visdial-diversity">Code</a>
    </span>
</p>
<img src="/img/visdial/visdial-rl-plus-plus.png">
<hr>

<a name="/multi-agent-comm"></a>
<h2 class="pubt">TarMAC: Targeted Multi-Agent Communication</h2>
<p class="pubd">
    <span class="authors">Abhishek Das, Théophile Gervet, Joshua Romoff, Dhruv Batra, Devi Parikh, Michael Rabbat, Joelle Pineau</span><br>
    <span class="conf">ICML 2019</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1810.11187">Paper</a>
        <a target="_blank" href="https://drive.google.com/open?id=1ZjKogiYrqFVuBmad3IzkNW18pvP2QcIG">Slides</a>
    </span>
</p>
<img src="/img/multi-agent-comm/model.jpg">
<br><br>
<img src="/img/multi-agent-comm/shapes.gif">
<hr>

<a name="/eqa-mp3d"></a>
<h2 class="pubt">Embodied Question Answering in Photorealistic Environments with Point Clouds</h2>
<p class="pubd">
    <span class="authors">
        Erik Wijmans*, Samyak Datta*, Oleksandr Maksymets*, Abhishek Das, Georgia Gkioxari, Stefan Lee, Irfan Essa, Devi Parikh, Dhruv Batra
    </span><br>
    <span class="conf">CVPR 2019 (Oral)</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1904.03461">Paper</a>
    </span>
</p>
<img src="/img/eqa/eqa-mp3d.png">
<hr>

<a name="/avsd"></a>
<h2 class="pubt">Audio-Visual Scene-Aware Dialog</h2>
<p class="pubd">
    <span class="authors">
        Huda Alamri, Vincent Cartillier, Abhishek Das,
        Jue Wang, Stefan Lee, Peter Anderson, Irfan Essa, Devi Parikh,
        Dhruv Batra, Anoop Cherian, Tim K. Marks, Chiori Hori
    </span><br>
    <span class="conf">CVPR 2019</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1901.09107">Paper</a>
        <a target="_blank" href="https://github.com/batra-mlp-lab/avsd">Code</a>
        <a target="_blank" href="http://video-dialog.com/">video-dialog.com</a>
    </span>
</p>
<img src="/img/avsd/avsd.jpg">
<hr>

<a name="/avsd_icassp"></a>
<h2 class="pubt">End-to-end Audio Visual Scene-Aware Dialog Using Multimodal Attention-based Video Features</h2>
<p class="pubd">
    <span class="authors">
            Chiori Hori, Huda Alamri, Jue Wang, Gordon Wichern, Takaaki Hori, Anoop Cherian, Tim K. Marks, Vincent Cartillier, Raphael Lopes, Abhishek Das, Irfan Essa, Dhruv Batra, Devi Parikh
    </span><br>
    <span class="conf">ICASSP 2019</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1806.08409">Paper</a>
        <a target="_blank" href="http://video-dialog.com/">video-dialog.com</a>
    </span>
</p>
<img src="/img/avsd/avsd_icassp.jpg">
<hr>

<a name="/eqa-modular"></a>
<h2 class="pubt">Neural Modular Control for Embodied Question Answering</h2>
<p class="pubd">
    <span class="authors">Abhishek Das, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra</span><br>
    <span class="conf">CoRL 2018 (Spotlight)</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1810.11181">Paper</a>
        <a target="_blank" href="https://embodiedqa.org/">embodiedqa.org</a>
        <a target="_blank" href="https://www.youtube.com/watch?v=xoHvho-YRgs&t=7330">Presentation video</a>
        <a target="_blank" href="https://drive.google.com/open?id=1xTvgpVNxG7MPZQe6jtXuYUIT2WPtoh0U">Slides</a>
    </span>
</p>

<img src="/img/eqa/eqa-modular.png">

<hr>
<a name="/embodied-qa"></a>
<h2 class="pubt">Embodied Question Answering</h2>
<p class="pubd">
    <span class="authors">Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra</span><br>
    <span class="conf">CVPR 2018 (Oral)</span><br>
    <span class="links">
        <a target="_blank" href="https://embodiedqa.org/paper.pdf">Paper</a>
        <a target="_blank" href="https://embodiedqa.org/">embodiedqa.org</a>
        <a target="_blank" href="https://github.com/facebookresearch/EmbodiedQA">Code</a>
        <a target="_blank" href="//youtu.be/gz2VoDrvX-A?t=1h19m58s">Presentation video</a>
        <a target="_blank" href="https://drive.google.com/open?id=1UacybW4p_8PDPNUvnEl05_89tbeG0ItP">Slides</a>
    </span>
    <!-- Press: -->
    <div class="row pressdiv" style="margin: 5px 0 0 0; line-height: 1.4em;">
        <a style="border-bottom: 0;" target="_blank" href="https://mlatgt.blog/2018/02/26/embodied-question-answering/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/mlgt.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Embodied Question Answering" by Abhishek Das</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://code.facebook.com/posts/1622140391226436/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/fair2.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"... a goal-driven approach to autonomous agents" by Dhruv Batra, Devi Parikh</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://www.technologyreview.com/s/611040/facebook-helped-create-an-ai-scavenger-hunt-that-could-lead-to-the-first-useful-home-robots/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 3px 0;">
                <img src="/img/logos/mittechreview.svg" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"... an AI scavenger hunt that could lead to the first useful home robots" by Will Knight</span>
            </div>
        </a>
    </div>
</p>

<img src="/img/eqa/teaser.jpg">

<hr>
<h2 class="pubt">Evaluating Visual Conversational Agents via Cooperative Human-AI Games</h2>
<p class="pubd">
    <span class="authors">Prithvijit Chattopadhyay<sup>*</sup>, Deshraj Yadav<sup>*</sup>, Viraj Prabhu, Arjun Chandrasekaran, Abhishek Das, Stefan Lee, Dhruv Batra, Devi Parikh</span><br>
    <span class="conf">HCOMP 2017</span><br>
    <span class="links">
        <a target="_blank" href="//arxiv.org/abs/1708.05122">Paper</a>
        <a target="_blank" href="//github.com/VT-vision-lab/guesswhich">Code</a>
    </span>
</p>

<img src="/img/guesswhich/teaser.jpg">

<a name="/visdial-rl"></a>

<hr>
<h2 class="pubt">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</h2>
<p class="pubd">
    <span class="authors">Abhishek Das<sup>*</sup>, Satwik Kottur<sup>*</sup>, Stefan Lee, José M.F. Moura, Dhruv Batra</span><br>
    <span class="conf">ICCV 2017 (Oral)</span><br>
    <span class="links">
        <a target="_blank" href="//arxiv.org/abs/1703.06585">Paper</a>
        <a target="_blank" href="//github.com/batra-mlp-lab/visdial-rl">Code</a>
        <a target="_blank" href="//www.youtube.com/watch?v=R4hugGnNr7s">Presentation video</a>
        <a target="_blank" href="https://drive.google.com/open?id=0B70NAN5i4ZHSaVBESEFHQW9vUk0">Slides</a>
    </span>
</p>

<img src="/img/visdial/qbot_abot.jpg">

<hr>
<h2 class="pubt">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</h2>
<p class="pubd">
    <span class="authors">Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra</span><br>
    <span class="conf">IJCV 2019, ICCV 2017, NIPS 2016 Interpretable ML for Complex Systems Workshop</span><br>
    <span class="links">
        <a target="_blank" href="//arxiv.org/abs/1610.02391">Paper</a>
        <a target="_blank" href="https://github.com/ramprs/grad-cam">Code</a>
        <a target="_blank" href="http://gradcam.cloudcv.org/">Demo</a>
    </span>
</p>

<img src="/img/grad-cam/teaser.png">

<a name="/visdial"></a>

<hr>
<h2 class="pubt">Visual Dialog</h2>
<p class="pubd" style="margin-bottom:20px;">
    <span class="authors">Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, José M.F. Moura, Devi Parikh, Dhruv Batra</span><br>
    <span class="conf">PAMI 2018, CVPR 2017 (Spotlight)</span><br>
    <span class="links">
        <a target="_blank" href="//arxiv.org/abs/1611.08669">Paper</a>
        <a target="_blank" href="//github.com/batra-mlp-lab/visdial">Code</a>
        <a target="_blank" href="http://visualdialog.org/">visualdialog.org</a>
        <a target="_blank" href="https://github.com/batra-mlp-lab/visdial-amt-chat">AMT chat interface</a>
        <a target="_blank" href="http://demo.visualdialog.org">Demo</a>
        <a target="_blank" href="//www.youtube.com/watch?v=I9OlorMh7wU">Presentation video</a>
        <a target="_blank" href="https://drive.google.com/open?id=0B70NAN5i4ZHSTWhRTTlMdVVIcFU">Slides</a>
    </span>
</p>

<img src="/img/visdial/teaser.png">

<!-- <div id="vimeo-embed">
    <iframe src="https://player.vimeo.com/video/193092429?byline=0&portrait=0&color=ffffff" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
</div> -->

<hr>
<h2 class="pubt">Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?</h2>

<p class="pubd">
    <span class="authors">Abhishek Das<sup>*</sup>, Harsh Agrawal<sup>*</sup>, C. Lawrence Zitnick, Devi Parikh, Dhruv Batra</span> <br>
    <span class="conf">CVIU 2017, EMNLP 2016, ICML 2016 Workshop on Visualization for Deep Learning</span><br>
    <span class="links">
        <a target="_blank" href="//arxiv.org/abs/1606.03556">Paper</a>
        <a target="_blank" href="https://abhishekdas.com/vqa-hat/">Project+Dataset</a>
        <a target="_blank" href="https://github.com/abhshkdz/neural-vqa-attention">neural-vqa-attention</a>
    </span>
    <!-- Press: -->
    <div class="row pressdiv" style="margin: 5px 0 0 0; line-height: 1.4em;">
        <a style="border-bottom: 0;" target="_blank" href="http://nautil.us/issue/40/learning/is-artificial-intelligence-permanently-inscrutable">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0; line-height: 1.1em;">
                <img src="/img/logos/nautilus.png" style="background: white; width: 57px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Is Artificial Intelligence Permanently Inscrutable?" by Aaron Bornstein</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="http://www.theverge.com/2016/7/12/12158238/first-click-deep-learning-algorithmic-black-boxes">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/theverge.png" style="margin-right: 5px; background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Deep learning is creating computer systems we don't fully understand" by James Vincent</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://www.newscientist.com/article/2095616-robot-eyes-and-humans-fix-on-different-things-to-decode-a-scene/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/newscientist.jpg" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Robot eyes and humans fix on different things to decode a scene" by Aviva Rutkin</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="http://www.techradar.com/news/world-of-tech/robots-and-humans-see-the-world-differently-but-we-don-t-know-why-1324165">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 0;">
                <img src="/img/logos/techradar.png" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"Robots and humans see the world differently – but we don't know why" by Duncan Geere</span>
            </div>
        </a>
        <a style="border-bottom: 0;" target="_blank" href="https://www.technologyreview.com/s/601819/ai-is-learning-to-see-the-world-but-not-the-way-humans-do/">
            <div class="col-lg-1 col-md-1 col-xs-2" style="padding: 3px 0;">
                <img src="/img/logos/mittechreview.svg" style="background: white; width: 60px;">
            </div>
            <div class="col-lg-11 col-md-11 col-xs-10">
                <span class="presslink">"AI Is Learning to See the World—But Not the Way Humans Do" by Jamie Condliffe</span>
            </div>
        </a>
    </div>
</p><img src="/img/vqa-hat/teaser.jpg">
<hr>

<a name="/talks"></a>

# Talks

<div class="row">
    <div class="col-xs-6">
        <p class="talkd">
            <img src="/img/talks/visdial_rl_iccv17.jpg">
        </p>
    </div>
    <div class="col-xs-6">
        <p class="talkd">
            <img src="/img/talks/embodiedqa_cvpr18_4.jpg">
        </p>
    </div>
</div>
<div class="row">
    <div class="col-xs-12">
        <div class="talkt">
            <a target="_blank" href="https://slideslive.com/38928261/probing-emergent-semantics-in-predictive-agents-via-question-answering">
                ICML 2020: Probing Emergent Semantics in Predictive Agents via Question Answering
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://slideslive.com/38917625/tarmac-targeted-multiagent-communication">
                ICML 2019 Imitation, Intent, and Interaction Workshop:
                Targeted Multi-Agent Communication
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://www.facebook.com/icml.imls/videos/444326646299556/">
                ICML 2019 Oral: Targeted Multi-Agent Communication
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://www.youtube.com/watch?v=WxYBp3Xr_Nc">
                Allen Institute for Artificial Intelligence: "Towards Agents that can See, Talk, and Act"
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://www.youtube.com/watch?v=xoHvho-YRgs&t=7330">
                CoRL 2018 Spotlight: Neural Modular Control for Embodied Question Answering
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://youtu.be/gz2VoDrvX-A?t=1h19m58s">
                CVPR 2018 Oral: Embodied Question Answering
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="http://on-demand.gputechconf.com/gtc/2018/video/S8582/">
                NVIDIA GTC 2018
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://www.youtube.com/watch?v=R4hugGnNr7s">
                ICCV 2017 Oral: Learning Cooperative Visual Dialog Agents with Deep RL
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://youtu.be/KAlGWMJnWyc?t=26m56s">
                Visual Question Answering Challenge Workshop, CVPR 2017
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://www.youtube.com/watch?v=I9OlorMh7wU">
                CVPR 2017 Spotlight: Visual Dialog
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="http://techtalks.tv/talks/towards-transparent-visual-question-answering-systems/63026/">
                Visualization for Deep Learning Workshop, ICML 2016
            </a>
        </div>
    </div>
</div>
<hr>

<a name="/projects"></a>

# Side projects

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="http://aipaygrad.es">aipaygrad.es</a></h2>
        <p class="talkd">
            aipaygrad.es provides statistics of industry job offers in Artificial Intelligence (AI).
            All data is anonymous, cross-verified against offer letters and will
            hopefully reduce information asymmetry.
            <a target="_blank" href="http://aipaygrad.es"><img style="margin-top: 10px;" src="/img/projects/ai-paygrades.png"></a>
        </p>
    </div>
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="http://aideadlin.es">aideadlin.es</a></h2>
        <p class="talkd">
            aideadlin.es is a webpage to keep track of CV/NLP/ML/AI conference deadlines. It's hosted on GitHub, and countdowns are automatically updated via pull requests to the data file in the repo.
            <a target="_blank" href="http://aideadlin.es"><img style="margin-top: 10px;" src="/img/projects/ai-deadlines-1547012831.png"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/neural-vqa-attention">neural-vqa-attention</a></h2>
        <p class="talkd">
            Torch implementation of an attention-based visual question answering model (Yang et al., CVPR16).
            The model looks at an image, reads a question, and comes up with an answer to the question and a heatmap of where it looked in the image to answer it.
            Some results <a href="https://computing.ece.vt.edu/~abhshkdz/neural-vqa-attention/figures/">here</a>.
            <a target="_blank" href="https://github.com/abhshkdz/neural-vqa-attention"><img class="project-img" src="/img/projects/neural-vqa-attention.jpg"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/neural-vqa">neural-vqa</a></h2>
        <p class="talkd">
            neural-vqa is an efficient, GPU-based Torch implementation of the visual question answering model from the NIPS 2015 paper 'Exploring Models and Data for Image Question Answering' by Ren et al.
            <a target="_blank" href="https://github.com/abhshkdz/neural-vqa"><img src="/img/projects/neural-vqa.jpg"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://erdos.sdslabs.co">Erdős</a></h2>
        <p class="talkd">
            Erdős by <a target="_blank" href="//sdslabs.co">SDSLabs</a> is a competitive math learning platform, similar in spirit to <a href="https://projecteuler.net/">Project Euler</a>, albeit more feature-packed (support for holding competitions, has a social layer) and prettier.
            <a target="_blank" href="https://erdos.sdslabs.co"><img style="margin-top:10px;" src="/img/projects/erdos.jpg"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-6">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/graf">graf</a></h2>
        <p class="talkd">
            graf plots pretty git contribution bar graphs in the terminal.
            <code>gem install graf</code> to install.
            <a target="_blank" href="https://github.com/abhshkdz/graf"><img style="margin-top:10px;" src="/img/projects/graf.gif"></a>
        </p>
    </div>
    <div class="col-sm-6">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/HackFlowy">HackFlowy</a></h2>
        <p class="talkd">
            Clone of <a href="//workflowy.com">WorkFlowy.com</a>, a beautiful, list-based note-taking website that has a 500-item monthly limit on the free tier :-(. This project is an open-source clone of WorkFlowy. "Make lists. Not war." :-)
            <a target="_blank" href="https://github.com/abhshkdz/HackFlowy"><img style="margin-top:40px;" src="/img/projects/hackflowy.png"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-6">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/AirMaps">AirMaps</a></h2>
        <p class="talkd">
            AirMaps was a fun hackathon project that lets users navigate through Google Earth with gestures and speech commands using a Kinect sensor. It was the <a target="_blank" href="https://blog.sdslabs.co/2014/02/code-fun-do">winning entry in Microsoft Code.Fun.Do</a>.
            <a target="_blank" href="https://github.com/abhshkdz/AirMaps"><img style="margin-top:10px;" src="/img/projects/airmaps.jpg"></a>
        </p>
    </div>
    <div class="col-sm-6">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/sdslabs/hackview">HackView</a></h2>
        <p class="talkd">
            Another fun hackathon-winning project built during Yahoo! HackU! 2012 that involves webRTC-based P2P video chat, and was faster than any other video chat provider (at the time, before Google launched Hangouts).
        </p>
    </div>
    <div class="col-sm-6">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/8tracks-downloader">8tracks-downloader</a></h2>
        <p class="talkd">
            Ugly-looking, but super-effective bash script for downloading entire playlists from 8tracks. (Still works as of 10/2016).
        </p>
    </div>
</div>

<script src="/js/jquery.min.js"></script>
<script type="text/javascript">
    $('ul:gt(0) li:gt(12)').hide();
    $('#read-more-button > a').click(function() {
        $('ul:gt(0) li:gt(12)').show();
        $('#read-more-button').hide();
    });
</script>

---

[1]: //mlp.cc.gatech.edu
[2]: ///www.cc.gatech.edu/~dbatra/
[3]: //www.cc.gatech.edu/~parikh/
[4]: //www.qbi.uq.edu.au/professor-geoffrey-goodhill
[5]: //researchers.uq.edu.au/researcher/2490
[6]: http://cns.qbi.uq.edu.au/
[7]: //developers.google.com/open-source/gsoc/
[8]: /posts/summer-of-code/
[9]: /posts/gsoc-reunion-2014/
[10]: //blog.sdslabs.co/2012/09/hacku
[11]: //blog.sdslabs.co/2014/02/code-fun-do
[12]: //www.facebook.com/SDSLabs/posts/527540147292475
[13]: /posts/deloitte-cctc-3/
[14]: /posts/google-india-community-summit/
[15]: //blog.sdslabs.co/2013/10/syntax-error-2013
[16]: //sdslabs.co/
[17]: //erdos.sdslabs.co/
[18]: //projecteuler.net/
[19]: //github.com/abhshkdz/neural-vqa
[20]: //github.com/abhshkdz/HackFlowy
[21]: //github.com/abhshkdz/graf
[22]: //github.com/abhshkdz
[23]: //twitter.com/abhshkdz
[24]: //instagram.com/abhshkdz
[25]: http://x.abhishekdas.com/
[26]: https://abhishekdas.com/vqa-hat/
[27]: http://arxiv.org/abs/1606.03556
[28]: https://www.newscientist.com/article/2095616-robot-eyes-and-humans-fix-on-different-things-to-decode-a-scene/
[29]: https://www.technologyreview.com/s/601819/ai-is-learning-to-see-the-world-but-not-the-way-humans-do/
[30]: http://www.theverge.com/2016/7/12/12158238/first-click-deep-learning-algorithmic-black-boxes
[31]: http://iitr.ac.in/
[32]: https://www.facebook.com/dhruv.batra.1253/posts/1783087161932290
[33]: https://drive.google.com/file/d/1nObeNzl-sTy8I5QN1Jv8wscebKLv-6RY/view?usp=sharing
[34]: http://aideadlin.es/
[35]: //github.com/abhshkdz/neural-vqa-attention
[36]: https://snapresearchfellowship.splashthat.com/
[37]: https://www.youtube.com/watch?v=R4hugGnNr7s
[38]: https://www.youtube.com/watch?v=I9OlorMh7wU
[39]: https://adoberesearch.ctlprojects.com/fellowship/previous-fellowship-award-winners/
[40]: https://embodiedqa.org/
[41]: https://youtu.be/KAlGWMJnWyc?t=26m56s
[42]: https://2018gputechconf.smarteventscloud.com/connect/sessionDetail.ww?SESSION_ID=152715
[43]: https://www.ic.gatech.edu/news/600684/three-ic-students-earn-snap-research-awards
[44]: https://www.ic.gatech.edu/news/601084/new-research-fellowships-offer-two-students-funding-access-adobes-creative-cloud
[45]: https://github.com/facebookresearch/House3D
[46]: https://gkioxari.github.io/
[47]: https://research.fb.com/people/parikh-devi/
[48]: https://research.fb.com/people/batra-dhruv/
[49]: https://lvatutorial.github.io/
[50]: http://acl2018.org/tutorials/#connecting-language-and-vis
[51]: http://visualqa.org/workshop.html
[52]: http://on-demand.gputechconf.com/gtc/2018/video/S8582/
[53]: https://visualdialog.org/challenge/2018
[54]: https://youtu.be/gz2VoDrvX-A?t=1h19m58s
[55]: https://research.fb.com/people/rabbat-mike/
[56]: https://www.cs.mcgill.ca/~jpineau/
[57]: https://visualdialog.org/challenge/2018#winners
[58]: https://www.youtube.com/watch?v=xoHvho-YRgs&t=7330
[fb-fellow-page]: https://research.fb.com/announcing-the-2019-facebook-fellows-and-emerging-scholars/
[joelle-corl18-talk-mention]: https://www.youtube.com/watch?v=FSsEqEJKo8A&t=3497
[visdial-challenge-2]: https://visualdialog.org/challenge/2019
[ic-gt-article]: https://www.ic.gatech.edu/news/617061/see-and-say-abhishek-das-working-provide-crucial-communication-tools-intelligent-agents
[caliper]: https://caliper.ai
[felix-hill]: https://fh295.github.io
[laura-rimell]: http://www.rimell.cc/laura/
[stephen-clark]: https://sites.google.com/site/stephenclark609/
[andrej-karpathy]: https://karpathy.ai/
[vigil19]: https://vigilworkshop.github.io/2019
[tarmac-icml-talk]: https://www.facebook.com/icml.imls/videos/444326646299556/
[mastodon]: https://mastodon.social/web/accounts/1011404
[conquerearth]: https://conquer.earth/abhshkdz
[qa-probing-icml20-talk]: https://slideslive.com/38928261/probing-emergent-semantics-in-predictive-agents-via-question-answering
[vigil20]: https://vigilworkshop.github.io
[ocp]: https://opencatalystproject.org
[ocp-cnbc]: https://www.cnbc.com/2020/10/14/facebook-to-use-ai-in-bid-to-improve-renewable-energy-storage.html
[ocp-engadget]: https://engadget.com/facebook-deploys-its-ai-to-find-green-energy-storage-solutions-130041147.html
[ocp-fortune]: https://fortune.com/2020/10/14/facebook-ai-open-catalyst-dataset-chemistry-renewable-energy/
[ocp-venturebeat]: https://venturebeat.com/2020/10/14/facebook-and-carnegie-mellon-launch-project-to-discover-better-ways-to-store-renewable-energy/
[aipaygrad.es]: https://aipaygrad.es
[sigma-xi-thesis-award]: https://cpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/0/283/files/2021/03/2021-Sigma-Xi-Research-Award-Winners.final_.pdf
[coc-dissertation-award]: https://sites.gatech.edu/gtcomputingawards2021/graduate-student-awards/
